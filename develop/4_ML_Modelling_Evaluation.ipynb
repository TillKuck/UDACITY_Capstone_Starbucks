{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Modelling & Evaluation of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, I will run the machine learning model for all three models:  \n",
    "   1) model_bogo  \n",
    "   2) model_discount \n",
    "   3) model_info\n",
    "\n",
    "As machine learning model, I will use XGBoost since it's especially good with tabular data and imblanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries, xgboost model and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from source.utils import load_data\n",
    "from source.model import XGBoostModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate XGBoost class\n",
    "model = XGBoostModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "bogo_data = load_data('../data/bogo_data.pkl')\n",
    "discount_data = load_data('../data/discount_data.pkl')\n",
    "info_data = load_data('../data/info_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bogo data\n",
    "\n",
    "We start off with the bogo data. Let's see how good our XGBoost model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   4%|▎         | 1/27 [00:54<23:46, 54.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "# Train xgboost model\n",
    "X_train, X_test, y_train, y_test = model.split_train_test(bogo_data, 'send_offer')\n",
    "model.pipeline = model.build_pipeline(X_train)\n",
    "model.fit_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy (always predict majority class): 0.7716386056438226\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.7047664216267489\n",
      "F1 Score: 0.7917711991971902\n",
      "ROC AUC Score: 0.6778287414930166\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 605  358]\n",
      " [ 887 2367]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.63      0.49       963\n",
      "           1       0.87      0.73      0.79      3254\n",
      "\n",
      "    accuracy                           0.70      4217\n",
      "   macro avg       0.64      0.68      0.64      4217\n",
      "weighted avg       0.76      0.70      0.72      4217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "model.evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### discount data\n",
    "\n",
    "Next, let's run the model for discount offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   4%|▎         | 1/27 [00:52<22:49, 52.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "# Train xgboost model\n",
    "X_train, X_test, y_train, y_test = model.split_train_test(discount_data, 'send_offer')\n",
    "model.pipeline = model.build_pipeline(X_train)\n",
    "model.fit_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy (always predict majority class): 0.7741585233441911\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.7064060803474485\n",
      "F1 Score: 0.7946537059538274\n",
      "ROC AUC Score: 0.6731504207573632\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 637  403]\n",
      " [ 949 2616]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.61      0.49      1040\n",
      "           1       0.87      0.73      0.79      3565\n",
      "\n",
      "    accuracy                           0.71      4605\n",
      "   macro avg       0.63      0.67      0.64      4605\n",
      "weighted avg       0.76      0.71      0.72      4605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "model.evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### info data\n",
    "\n",
    "Lastly, let's run the model for informational offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   4%|▎         | 1/27 [00:49<21:27, 49.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "# Train xgboost model\n",
    "X_train, X_test, y_train, y_test = model.split_train_test(info_data, 'send_offer')\n",
    "model.pipeline = model.build_pipeline(X_train)\n",
    "model.fit_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy (always predict majority class): 0.5826659038901603\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.575228832951945\n",
      "F1 Score: 0.5372390152695544\n",
      "ROC AUC Score: 0.5774402141600405\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1149  888]\n",
      " [ 597  862]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.61      2037\n",
      "           1       0.49      0.59      0.54      1459\n",
      "\n",
      "    accuracy                           0.58      3496\n",
      "   macro avg       0.58      0.58      0.57      3496\n",
      "weighted avg       0.59      0.58      0.58      3496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "model.evaluate(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
